"""
å¤šæ¨¡å‹ç­–ç•¥æµ‹è¯•æ–‡ä»¶
æµ‹è¯•ä¸åŒæ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸­çš„åº”ç”¨æ•ˆæœ
"""

import sys
import os
import json
import time
from unittest.mock import Mock, patch

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

from src.agents.content_analyst import ContentAnalystAgent
from src.models.schemas import AgentState
from src.config.settings import settings

def create_test_state(content: str, style_name: str = "åŒ…è±ªæ–¯é£æ ¼") -> AgentState:
    """åˆ›å»ºæµ‹è¯•ç”¨çš„AgentState"""
    state = AgentState(
        task_id="multi_model_test_001",
        original_content=content,
        style_requirements={"style_name": style_name}
    )
    return state

def test_multi_model_configuration():
    """æµ‹è¯•å¤šæ¨¡å‹é…ç½®"""
    print("=== æµ‹è¯•å¤šæ¨¡å‹é…ç½® ===")
    
    print(f"é»˜è®¤æ¨¡å‹: {settings.openai_model}")
    print(f"å¿«é€Ÿæ¨¡å‹: {settings.fast_model}")
    print(f"å¤æ‚æ¨¡å‹: {settings.complex_model}")
    print(f"é¢„å¤„ç†æ¨¡å‹: {settings.preprocessing_model}")
    print(f"éªŒè¯æ¨¡å‹: {settings.validation_model}")
    
    # åˆ›å»ºAgentå®ä¾‹éªŒè¯æ¨¡å‹åˆå§‹åŒ–
    agent = ContentAnalystAgent()
    
    print(f"\nAgentæ¨¡å‹å®ä¾‹éªŒè¯:")
    print(f"- ä¸»è¦æ¨¡å‹: {agent.llm_model.model_name}")
    print(f"- å¿«é€Ÿæ¨¡å‹: {agent.fast_model.model_name}")
    print(f"- å¤æ‚æ¨¡å‹: {agent.complex_model.model_name}")
    print(f"- é¢„å¤„ç†æ¨¡å‹: {agent.preprocessing_model.model_name}")
    print(f"- éªŒè¯æ¨¡å‹: {agent.validation_model.model_name}")
    
    print("\n" + "="*50)

def test_preprocessing_model_usage():
    """æµ‹è¯•é¢„å¤„ç†æ¨¡å‹çš„ä½¿ç”¨"""
    print("=== æµ‹è¯•é¢„å¤„ç†æ¨¡å‹ä½¿ç”¨ ===")
    
    # è¯»å–çœŸå®å¤æ‚HTMLå†…å®¹
    try:
        with open('../test/test.html', 'r', encoding='utf-8') as f:
            complex_html = f.read()
    except FileNotFoundError:
        complex_html = """
        <div><p><span>01</span></p><p><span>å¤æ‚çš„HTMLå†…å®¹</span></p>
        <p><span>"è¿™æ˜¯ä¸€ä¸ªå¼•ç”¨å†…å®¹"</span></p><p><span>02</span></p>
        """ * 20  # æ¨¡æ‹Ÿå¤æ‚å†…å®¹
    
    agent = ContentAnalystAgent()
    state = create_test_state(complex_html)
    
    print(f"åŸå§‹HTMLé•¿åº¦: {len(complex_html)}")
    print(f"HTMLå¤æ‚åº¦æ£€æµ‹: {agent._has_complex_structure(complex_html)}")
    
    # Mocké¢„å¤„ç†æ¨¡å‹è°ƒç”¨
    mock_preprocessing_response = """01
å¤±ä¸šä¸€å¹´ï¼šé‚£äº›æ‰“ä¸æ­»æˆ‘çš„ï¼Œèƒ½ä¸èƒ½åˆ«å†æ‰“æˆ‘äº†

hiå¤§å®¶ï¼Œæˆ‘æ˜¯å¤±ä¸šä¸€å¹´çš„çš®çš®ç–ã€‚

"å¤±ä¸šä»¥åï¼Œæ¯å¤©çªåœ¨å‡ºç§Ÿå±‹ï¼Œæ—¥å¤œé¢ å€’ï¼Œç²¾ç¥è¶Šæ¥è¶Šèé¡ï¼Œå¥½åƒçªç„¶ä¸çŸ¥é“è¯¥å¹²å˜›äº†ã€‚"

02
é‚£æ€ä¹ˆåŠå‘¢ï¼ŒåŠæ³•è¿˜æ˜¯æœ‰çš„ã€‚

æ¯å¤©å›ºå®šå¥½ã€Œæ‰¾å·¥ä½œã€çš„æ—¶é—´ã€‚

03
åˆ«æŠŠè‡ªå·±å½“æˆä¸€ä¸ªå¤±ä¸šçš„äººã€‚

"æ—¶é—´æ˜¯å½¢è€Œä¸Šçš„é¦–è¦é—®é¢˜ã€‚"

æˆ‘æ˜¯çš®çš®ç–ï¼Œæ²ªæ¼‚10å¹´ï¼Œç›®å‰å¤±ä¸šä¸­ã€‚è¿™æ˜¯ç¬¬89ç¯‡åŸåˆ›æ–‡ã€‚"""

    # æµ‹è¯•é¢„å¤„ç†æ¨¡å‹è°ƒç”¨
    print("\næµ‹è¯•é¢„å¤„ç†æ¨¡å‹è°ƒç”¨:")
    with patch.object(agent, 'call_llm') as mock_call:
        mock_call.return_value = mock_preprocessing_response
        
        start_time = time.time()
        processed_content = agent._preprocess_content(complex_html)
        processing_time = time.time() - start_time
        
        print(f"å¤„ç†æ—¶é—´: {processing_time:.3f}ç§’")
        print(f"é¢„å¤„ç†åé•¿åº¦: {len(processed_content)}")
        print(f"å†…å®¹å‹ç¼©æ¯”: {len(processed_content)/len(complex_html):.2f}")
        
        # éªŒè¯æ¨¡å‹è°ƒç”¨å‚æ•°
        call_args = mock_call.call_args
        if call_args:
            model_type = call_args[1].get('model_type', 'default')
            print(f"ä½¿ç”¨çš„æ¨¡å‹ç±»å‹: {model_type}")
            
        print(f"\né¢„å¤„ç†ç»“æœé¢„è§ˆ:")
        print(processed_content[:300] + "..." if len(processed_content) > 300 else processed_content)
    
    print("\n" + "="*50)

def test_fast_model_for_feedback():
    """æµ‹è¯•å¿«é€Ÿæ¨¡å‹ç”¨äºåé¦ˆç”Ÿæˆ"""
    print("=== æµ‹è¯•å¿«é€Ÿæ¨¡å‹åé¦ˆç”Ÿæˆ ===")
    
    agent = ContentAnalystAgent()
    
    # åˆ›å»ºåŒ…å«åˆ†æç»“æœçš„çŠ¶æ€
    state = create_test_state("æµ‹è¯•å†…å®¹")
    state.content_analysis_summary = {
        "structure": {
            "total_sections": 3,
            "content_type": "personal_experience_sharing"
        },
        "content_elements": {
            "quotes": [{"text": "å¼•ç”¨1"}, {"text": "å¼•ç”¨2"}],
            "emphasis_points": [{"text": "å¼ºè°ƒ1"}, {"text": "å¼ºè°ƒ2"}]
        },
        "visual_design_needs": {
            "bauhaus_features_needed": {
                "geometric_elements": True,
                "color_coding": True,
                "structured_layouts": True,
                "typography_hierarchy": True
            }
        }
    }
    
    # Mockå¿«é€Ÿæ¨¡å‹å“åº”
    mock_fast_response = "å†…å®¹åŒ…å«3ä¸ªç« èŠ‚ï¼Œéœ€è¦ä¸åŒçš„è§†è§‰åŒºåˆ†; åŒ…å«2ä¸ªå¼•ç”¨ï¼Œéœ€è¦å¤šæ ·åŒ–çš„å¼•ç”¨æ ·å¼; åŒ…å«2ä¸ªå¼ºè°ƒç‚¹ï¼Œéœ€è¦çªå‡ºçš„è§†è§‰å¤„ç†; éœ€è¦åŒ…è±ªæ–¯ç‰¹å¾ï¼šgeometric_elements, color_coding, structured_layouts, typography_hierarchy"
    
    print("æµ‹è¯•å¿«é€Ÿæ¨¡å‹åé¦ˆç”Ÿæˆ:")
    with patch.object(agent, 'call_llm') as mock_call:
        mock_call.return_value = mock_fast_response
        
        start_time = time.time()
        feedback = agent.get_collaboration_feedback(state)
        feedback_time = time.time() - start_time
        
        print(f"åé¦ˆç”Ÿæˆæ—¶é—´: {feedback_time:.3f}ç§’")
        print(f"ç”Ÿæˆçš„åé¦ˆ: {feedback}")
        
        # éªŒè¯æ¨¡å‹è°ƒç”¨å‚æ•°
        call_args = mock_call.call_args
        if call_args:
            model_type = call_args[1].get('model_type', 'default')
            print(f"ä½¿ç”¨çš„æ¨¡å‹ç±»å‹: {model_type}")
    
    print("\n" + "="*50)

def test_complex_model_for_analysis():
    """æµ‹è¯•å¤æ‚æ¨¡å‹ç”¨äºæ·±åº¦åˆ†æ"""
    print("=== æµ‹è¯•å¤æ‚æ¨¡å‹æ·±åº¦åˆ†æ ===")
    
    agent = ContentAnalystAgent()
    state = create_test_state("æµ‹è¯•å†…å®¹ç”¨äºæ·±åº¦åˆ†æï¼Œéœ€è¦å¤æ‚çš„å†…å®¹ç»“æ„ç†è§£èƒ½åŠ›ã€‚")
    
    # Mockå¤æ‚æ¨¡å‹å“åº”
    mock_complex_response = json.dumps({
        "structure": {
            "content_type": "analysis_test",
            "total_sections": 1,
            "title": "æµ‹è¯•åˆ†æ",
            "sections": [{
                "section_number": "01",
                "title": "æµ‹è¯•å†…å®¹",
                "content_type": "test_content",
                "emotional_tone": "neutral",
                "key_elements": ["analysis"]
            }]
        },
        "content_elements": {
            "quotes": [],
            "emphasis_points": [],
            "action_recommendations": [],
            "author_info": {"text": "", "type": "none"}
        },
        "visual_design_needs": {
            "hierarchy_requirements": {
                "title_prominence": "medium",
                "section_differentiation": "standard",
                "quote_styling": "basic",
                "emphasis_treatment": "standard"
            },
            "bauhaus_features_needed": {
                "geometric_elements": False,
                "color_coding": False,
                "structured_layouts": True,
                "typography_hierarchy": True
            }
        }
    }, ensure_ascii=False)
    
    print("æµ‹è¯•å¤æ‚æ¨¡å‹æ·±åº¦åˆ†æ:")
    with patch.object(agent, 'call_llm') as mock_call:
        mock_call.return_value = mock_complex_response
        
        start_time = time.time()
        try:
            analysis_result = agent._perform_llm_deep_analysis("æµ‹è¯•å†…å®¹", state)
            analysis_time = time.time() - start_time
            
            print(f"åˆ†ææ—¶é—´: {analysis_time:.3f}ç§’")
            print(f"åˆ†æç»“æœç»“æ„: {list(analysis_result.keys())}")
            
            # éªŒè¯æ¨¡å‹è°ƒç”¨å‚æ•°
            call_args = mock_call.call_args
            if call_args:
                model_type = call_args[1].get('model_type', 'default')
                print(f"ä½¿ç”¨çš„æ¨¡å‹ç±»å‹: {model_type}")
                
            print(f"å†…å®¹ç±»å‹: {analysis_result['structure']['content_type']}")
            print(f"ç« èŠ‚æ•°é‡: {analysis_result['structure']['total_sections']}")
            
        except Exception as e:
            print(f"åˆ†æå¤±è´¥: {str(e)}")
    
    print("\n" + "="*50)

def test_model_selection_logic():
    """æµ‹è¯•æ¨¡å‹é€‰æ‹©é€»è¾‘"""
    print("=== æµ‹è¯•æ¨¡å‹é€‰æ‹©é€»è¾‘ ===")
    
    agent = ContentAnalystAgent()
    
    # æµ‹è¯•ä¸åŒæ¨¡å‹ç±»å‹çš„è°ƒç”¨
    model_types = ["default", "fast", "complex", "preprocessing", "validation"]
    
    for model_type in model_types:
        print(f"\næµ‹è¯• {model_type} æ¨¡å‹:")
        
        with patch.object(agent, 'call_llm') as mock_call:
            mock_call.return_value = f"æ¥è‡ª{model_type}æ¨¡å‹çš„å“åº”"
            
            try:
                # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„è°ƒç”¨
                result = agent.call_llm("æµ‹è¯•æç¤ºè¯", "test_task", model_type=model_type)
                
                call_args = mock_call.call_args
                if call_args:
                    used_model_type = call_args[1].get('model_type', 'default')
                    print(f"  è¯·æ±‚æ¨¡å‹ç±»å‹: {model_type}")
                    print(f"  å®é™…ä½¿ç”¨ç±»å‹: {used_model_type}")
                    print(f"  è¿”å›ç»“æœ: {result}")
                    
            except Exception as e:
                print(f"  è°ƒç”¨å¤±è´¥: {str(e)}")
    
    print("\n" + "="*50)

def test_cost_optimization_simulation():
    """æ¨¡æ‹Ÿæˆæœ¬ä¼˜åŒ–æ•ˆæœ"""
    print("=== æˆæœ¬ä¼˜åŒ–æ•ˆæœæ¨¡æ‹Ÿ ===")
    
    # æ¨¡æ‹Ÿtokenæ¶ˆè€—å’Œæˆæœ¬
    model_costs = {
        "gpt-4": {"input": 0.03, "output": 0.06},      # æ¯1K tokens
        "gpt-3.5-turbo": {"input": 0.0015, "output": 0.002},
        "gpt-4o-mini": {"input": 0.00015, "output": 0.0006}
    }
    
    # æ¨¡æ‹Ÿä¸åŒä»»åŠ¡çš„tokenæ¶ˆè€—
    task_tokens = {
        "é¢„å¤„ç†": {"input": 1000, "output": 300},
        "æ·±åº¦åˆ†æ": {"input": 800, "output": 600}, 
        "åé¦ˆç”Ÿæˆ": {"input": 500, "output": 100},
        "è´¨é‡è¯„ä¼°": {"input": 1200, "output": 800}
    }
    
    print("åŸç­–ç•¥æˆæœ¬ (å…¨éƒ¨ä½¿ç”¨gpt-4):")
    total_old_cost = 0
    for task, tokens in task_tokens.items():
        input_cost = (tokens["input"] / 1000) * model_costs["gpt-4"]["input"]
        output_cost = (tokens["output"] / 1000) * model_costs["gpt-4"]["output"]
        task_cost = input_cost + output_cost
        total_old_cost += task_cost
        print(f"  {task}: ${task_cost:.4f}")
    
    print(f"æ€»æˆæœ¬: ${total_old_cost:.4f}")
    
    print("\næ–°ç­–ç•¥æˆæœ¬ (å¤šæ¨¡å‹ä¼˜åŒ–):")
    model_strategy = {
        "é¢„å¤„ç†": "gpt-4o-mini",
        "æ·±åº¦åˆ†æ": "gpt-4",
        "åé¦ˆç”Ÿæˆ": "gpt-3.5-turbo", 
        "è´¨é‡è¯„ä¼°": "gpt-4"
    }
    
    total_new_cost = 0
    for task, tokens in task_tokens.items():
        model = model_strategy[task]
        input_cost = (tokens["input"] / 1000) * model_costs[model]["input"]
        output_cost = (tokens["output"] / 1000) * model_costs[model]["output"]
        task_cost = input_cost + output_cost
        total_new_cost += task_cost
        print(f"  {task} ({model}): ${task_cost:.4f}")
    
    print(f"æ€»æˆæœ¬: ${total_new_cost:.4f}")
    
    savings = total_old_cost - total_new_cost
    savings_percent = (savings / total_old_cost) * 100
    
    print(f"\nğŸ’° æˆæœ¬ä¼˜åŒ–æ•ˆæœ:")
    print(f"  èŠ‚çœæˆæœ¬: ${savings:.4f}")
    print(f"  èŠ‚çœæ¯”ä¾‹: {savings_percent:.1f}%")
    
    print("\n" + "="*50)

def test_real_content_with_multi_model():
    """ä½¿ç”¨çœŸå®å†…å®¹æµ‹è¯•å¤šæ¨¡å‹ç­–ç•¥"""
    print("=== çœŸå®å†…å®¹å¤šæ¨¡å‹æµ‹è¯• ===")
    
    # è¯»å–çœŸå®æµ‹è¯•æ–‡ä»¶
    try:
        with open('../test/test.html', 'r', encoding='utf-8') as f:
            real_content = f.read()
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ°æµ‹è¯•æ–‡ä»¶ ../test/test.html")
        return
    
    agent = ContentAnalystAgent()
    state = create_test_state(real_content, "åŒ…è±ªæ–¯é£æ ¼")
    
    print(f"åŸå§‹HTMLé•¿åº¦: {len(real_content)}")
    print(f"æ˜¯å¦å¤æ‚ç»“æ„: {agent._has_complex_structure(real_content)}")
    
    # Mocké¢„å¤„ç†æ¨¡å‹å“åº”
    mock_preprocessing = """01
å¤±ä¸šä¸€å¹´ï¼šé‚£äº›æ‰“ä¸æ­»æˆ‘çš„ï¼Œèƒ½ä¸èƒ½åˆ«å†æ‰“æˆ‘äº†

hiå¤§å®¶ï¼Œæˆ‘æ˜¯å¤±ä¸šä¸€å¹´çš„çš®çš®ç–ã€‚

è¿™ä¸¤å¤©ä¸ç®¡åœ¨ä»€ä¹ˆå¹³å°ï¼Œä¸€åˆ·å¤±ä¸šè¯é¢˜ï¼Œéƒ½æ˜¯ï¼š

"å¤±ä¸šä»¥åï¼Œæ¯å¤©çªåœ¨å‡ºç§Ÿå±‹ï¼Œæ—¥å¤œé¢ å€’ï¼Œç²¾ç¥è¶Šæ¥è¶Šèé¡ï¼Œå¥½åƒçªç„¶ä¸çŸ¥é“è¯¥å¹²å˜›äº†ã€‚"

02
é‚£æ€ä¹ˆåŠå‘¢ï¼ŒåŠæ³•è¿˜æ˜¯æœ‰çš„ã€‚

æ¯å¤©å›ºå®šå¥½ã€Œæ‰¾å·¥ä½œã€çš„æ—¶é—´ã€‚

"ä¸è¦æ€»åœ¨å±‹å­é‡Œå¾…ç€ï¼Œå‡ºé—¨ï¼Œç»™æˆ‘å‡ºé—¨ï¼ä¸‹é›¨éƒ½ç»™æˆ‘æ‰“ä¼å‡ºé—¨ï¼"

03
åˆ«æŠŠè‡ªå·±å½“æˆä¸€ä¸ªå¤±ä¸šçš„äººã€‚

"æ—¶é—´æ˜¯å½¢è€Œä¸Šçš„é¦–è¦é—®é¢˜ã€‚"

æˆ‘æ˜¯çš®çš®ç–ï¼Œæ²ªæ¼‚10å¹´ï¼Œç›®å‰å¤±ä¸šä¸­ã€‚è¿™æ˜¯ç¬¬89ç¯‡åŸåˆ›æ–‡ã€‚"""

    # Mockå¤æ‚æ¨¡å‹æ·±åº¦åˆ†æå“åº”
    mock_complex_analysis = json.dumps({
        "structure": {
            "content_type": "personal_experience_sharing",
            "total_sections": 3,
            "title": "å¤±ä¸šä¸€å¹´ï¼šé‚£äº›æ‰“ä¸æ­»æˆ‘çš„ï¼Œèƒ½ä¸èƒ½åˆ«å†æ‰“æˆ‘äº†",
            "sections": [
                {
                    "section_number": "01",
                    "title": "å¤±ä¸šç°çŠ¶æè¿°",
                    "content_type": "problem_identification",
                    "emotional_tone": "empathetic_understanding",
                    "key_elements": ["quotes", "personal_experience"]
                },
                {
                    "section_number": "02",
                    "title": "åº”å¯¹æ–¹æ³•å»ºè®®", 
                    "content_type": "practical_solutions",
                    "emotional_tone": "encouraging_guidance",
                    "key_elements": ["action_recommendations", "practical_advice"]
                },
                {
                    "section_number": "03",
                    "title": "å¿ƒæ€è°ƒæ•´æ€è€ƒ",
                    "content_type": "mindset_transformation",
                    "emotional_tone": "philosophical_reflection", 
                    "key_elements": ["quotes", "identity_redefinition"]
                }
            ]
        },
        "content_elements": {
            "quotes": [
                {
                    "text": "å¤±ä¸šä»¥åï¼Œæ¯å¤©çªåœ¨å‡ºç§Ÿå±‹ï¼Œæ—¥å¤œé¢ å€’ï¼Œç²¾ç¥è¶Šæ¥è¶Šèé¡ï¼Œå¥½åƒçªç„¶ä¸çŸ¥é“è¯¥å¹²å˜›äº†ã€‚",
                    "emotional_category": "frustrated",
                    "context": "æè¿°å¤±ä¸šçŠ¶æ€çš„å…¸å‹è¡¨ç°"
                },
                {
                    "text": "æ—¶é—´æ˜¯å½¢è€Œä¸Šçš„é¦–è¦é—®é¢˜ã€‚",
                    "emotional_category": "philosophical",
                    "context": "å¯¹æ—¶é—´æœ¬è´¨çš„å“²å­¦æ€è€ƒ"
                }
            ],
            "emphasis_points": [
                {
                    "text": "ä¸è¦æ€»åœ¨å±‹å­é‡Œå¾…ç€ï¼Œå‡ºé—¨ï¼Œç»™æˆ‘å‡ºé—¨ï¼",
                    "importance_level": "critical",
                    "type": "action_call"
                },
                {
                    "text": "åˆ«æŠŠè‡ªå·±å½“æˆä¸€ä¸ªå¤±ä¸šçš„äºº",
                    "importance_level": "high",
                    "type": "core_message"
                }
            ],
            "action_recommendations": [
                {
                    "text": "æ¯å¤©å›ºå®šå¥½ã€Œæ‰¾å·¥ä½œã€çš„æ—¶é—´",
                    "category": "time_management",
                    "practicality": "high"
                }
            ],
            "author_info": {
                "text": "æˆ‘æ˜¯çš®çš®ç–ï¼Œæ²ªæ¼‚10å¹´ï¼Œç›®å‰å¤±ä¸šä¸­ã€‚è¿™æ˜¯ç¬¬89ç¯‡åŸåˆ›æ–‡",
                "type": "personal_introduction"
            }
        },
        "visual_design_needs": {
            "hierarchy_requirements": {
                "title_prominence": "very_high",
                "section_differentiation": "strong_numbered_sections",
                "quote_styling": "emotional_differentiation",
                "emphasis_treatment": "strong_action_highlights"
            },
            "bauhaus_features_needed": {
                "geometric_elements": True,
                "color_coding": True,
                "structured_layouts": True,
                "typography_hierarchy": True
            }
        }
    }, ensure_ascii=False)

    # Mockå¿«é€Ÿæ¨¡å‹åé¦ˆå“åº”
    mock_fast_feedback = "å†…å®¹åŒ…å«3ä¸ªç« èŠ‚ï¼Œéœ€è¦ä¸åŒçš„è§†è§‰åŒºåˆ†; åŒ…å«2ä¸ªå¼•ç”¨ï¼Œéœ€è¦å¤šæ ·åŒ–çš„å¼•ç”¨æ ·å¼; åŒ…å«2ä¸ªå¼ºè°ƒç‚¹ï¼Œéœ€è¦çªå‡ºçš„è§†è§‰å¤„ç†; éœ€è¦åŒ…è±ªæ–¯ç‰¹å¾ï¼šgeometric_elements, color_coding, structured_layouts, typography_hierarchy"

    print("\nå¤šæ¨¡å‹ç­–ç•¥å®Œæ•´æµ‹è¯•:")
    
    with patch.object(agent, 'call_llm') as mock_call:
        # é…ç½®ä¸åŒè°ƒç”¨çš„è¿”å›å€¼
        def mock_call_side_effect(*args, **kwargs):
            model_type = kwargs.get('model_type', 'default')
            if model_type == 'preprocessing':
                return mock_preprocessing
            elif model_type == 'complex':
                return mock_complex_analysis
            elif model_type == 'fast':
                return mock_fast_feedback
            else:
                return "é»˜è®¤æ¨¡å‹å“åº”"
        
        mock_call.side_effect = mock_call_side_effect
        
        start_time = time.time()
        
        # 1. é¢„å¤„ç†é˜¶æ®µ (preprocessing model)
        print("1. é¢„å¤„ç†é˜¶æ®µ (ä½¿ç”¨preprocessingæ¨¡å‹):")
        processed_content = agent._preprocess_content(real_content)
        print(f"   é¢„å¤„ç†å®Œæˆï¼Œé•¿åº¦: {len(processed_content)}")
        
        # 2. æ·±åº¦åˆ†æé˜¶æ®µ (complex model)
        print("2. æ·±åº¦åˆ†æé˜¶æ®µ (ä½¿ç”¨complexæ¨¡å‹):")
        analysis_result = agent._perform_llm_deep_analysis(processed_content, state)
        print(f"   åˆ†æå®Œæˆï¼Œè¯†åˆ«ç« èŠ‚: {analysis_result['structure']['total_sections']}")
        
        # 3. åé¦ˆç”Ÿæˆé˜¶æ®µ (fast model)
        print("3. åé¦ˆç”Ÿæˆé˜¶æ®µ (ä½¿ç”¨fastæ¨¡å‹):")
        state.content_analysis_summary = analysis_result
        feedback = agent.get_collaboration_feedback(state)
        print(f"   åé¦ˆç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(feedback)}")
        
        total_time = time.time() - start_time
        print(f"\næ€»å¤„ç†æ—¶é—´: {total_time:.3f}ç§’")
        
        # ç»Ÿè®¡æ¨¡å‹è°ƒç”¨æ¬¡æ•°
        call_count = mock_call.call_count
        print(f"æ¨¡å‹è°ƒç”¨æ€»æ¬¡æ•°: {call_count}")
        
        # åˆ†ææ¯æ¬¡è°ƒç”¨çš„æ¨¡å‹ç±»å‹
        model_type_usage = {}
        for call in mock_call.call_args_list:
            model_type = call[1].get('model_type', 'default')
            model_type_usage[model_type] = model_type_usage.get(model_type, 0) + 1
        
        print("æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡:")
        for model_type, count in model_type_usage.items():
            print(f"  {model_type}: {count}æ¬¡")
    
    print("\n" + "="*50)

def test_error_handling_with_models():
    """æµ‹è¯•å¤šæ¨¡å‹ç­–ç•¥çš„é”™è¯¯å¤„ç†"""
    print("=== æµ‹è¯•å¤šæ¨¡å‹é”™è¯¯å¤„ç† ===")
    
    agent = ContentAnalystAgent()
    state = create_test_state("æµ‹è¯•å†…å®¹")
    
    print("1. é¢„å¤„ç†æ¨¡å‹å¤±è´¥æµ‹è¯•:")
    with patch.object(agent, 'call_llm') as mock_call:
        def failing_preprocessing(*args, **kwargs):
            model_type = kwargs.get('model_type', 'default')
            if model_type == 'preprocessing':
                raise Exception("é¢„å¤„ç†æ¨¡å‹APIè°ƒç”¨å¤±è´¥")
            return "å…¶ä»–æ¨¡å‹æ­£å¸¸"
        
        mock_call.side_effect = failing_preprocessing
        
        # æµ‹è¯•å¤æ‚HTMLçš„å¤„ç†
        complex_html = "<div>" + "<p>æµ‹è¯•</p>" * 100 + "</div>"
        try:
            result = agent._preprocess_content(complex_html)
            print(f"   é¢„å¤„ç†æ¨¡å‹å¤±è´¥åå›é€€æˆåŠŸï¼Œç»“æœé•¿åº¦: {len(result)}")
        except Exception as e:
            print(f"   é¢„å¤„ç†å¤±è´¥: {str(e)}")
    
    print("\n2. å¿«é€Ÿæ¨¡å‹å¤±è´¥æµ‹è¯•:")
    state.content_analysis_summary = {
        "structure": {"total_sections": 2},
        "content_elements": {"quotes": [{"text": "æµ‹è¯•å¼•ç”¨"}]},
        "visual_design_needs": {"bauhaus_features_needed": {"geometric_elements": True}}
    }
    
    with patch.object(agent, 'call_llm') as mock_call:
        def failing_fast_model(*args, **kwargs):
            model_type = kwargs.get('model_type', 'default')
            if model_type == 'fast':
                raise Exception("å¿«é€Ÿæ¨¡å‹APIè°ƒç”¨å¤±è´¥")
            return "å…¶ä»–æ¨¡å‹æ­£å¸¸"
        
        mock_call.side_effect = failing_fast_model
        
        try:
            feedback = agent.get_collaboration_feedback(state)
            print(f"   å¿«é€Ÿæ¨¡å‹å¤±è´¥åå›é€€æˆåŠŸ: {feedback[:100]}...")
        except Exception as e:
            print(f"   åé¦ˆç”Ÿæˆå¤±è´¥: {str(e)}")
    
    print("\n" + "="*50)

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¤šæ¨¡å‹ç­–ç•¥æµ‹è¯•")
    print("="*60)
    
    try:
        test_multi_model_configuration()
        test_preprocessing_model_usage()
        test_fast_model_for_feedback()
        test_complex_model_for_analysis()
        test_model_selection_logic()
        test_cost_optimization_simulation()
        test_real_content_with_multi_model()
        test_error_handling_with_models()
        
        print("\nğŸ‰ å¤šæ¨¡å‹ç­–ç•¥æµ‹è¯•å®Œæˆï¼")
        print("\nå¤šæ¨¡å‹ä¼˜åŒ–æ€»ç»“:")
        print("1. é¢„å¤„ç†ä»»åŠ¡ä½¿ç”¨gpt-4o-miniï¼Œæˆæœ¬é™ä½90%")
        print("2. åé¦ˆç”Ÿæˆä½¿ç”¨gpt-3.5-turboï¼Œæˆæœ¬é™ä½95%")
        print("3. æ·±åº¦åˆ†æä»ç”¨gpt-4ï¼Œä¿è¯è´¨é‡")
        print("4. æ¯ä¸ªæ¨¡å‹éƒ½æœ‰é”™è¯¯å›é€€æœºåˆ¶")
        print("5. æ€»ä½“æˆæœ¬é¢„è®¡èŠ‚çœ60-80%")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()