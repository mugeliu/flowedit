"""
ContentAnalyst Agent è°ƒè¯•æµ‹è¯•æ–‡ä»¶
ç”¨äºç†è§£å’Œæµ‹è¯• ContentAnalyst çš„å·¥ä½œåŸç†
"""

import sys
import os
import json
from unittest.mock import Mock, patch

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

from src.agents.content_analyst import ContentAnalystAgent
from src.models.schemas import AgentState

def create_test_state(content: str, style_name: str = "åŒ…è±ªæ–¯é£æ ¼") -> AgentState:
    """åˆ›å»ºæµ‹è¯•ç”¨çš„AgentState"""
    state = AgentState(
        task_id="test_task_001",
        original_content=content,
        style_requirements={"style_name": style_name}
    )
    return state

def test_html_preprocessing():
    """æµ‹è¯•HTMLå†…å®¹é¢„å¤„ç†åŠŸèƒ½"""
    print("=== æµ‹è¯•HTMLé¢„å¤„ç†åŠŸèƒ½ ===")
    
    agent = ContentAnalystAgent()
    
    # æµ‹è¯•HTMLå†…å®¹
    html_content = """
    <div>
        <h1>æ—¶é—´ç®¡ç†çš„è‰ºæœ¯</h1>
        <p>01</p>
        <p>æ—¶é—´æ˜¯æœ€çè´µçš„èµ„æºï¼Œæ¯ä¸ªäººéƒ½æ‹¥æœ‰ç›¸åŒçš„24å°æ—¶ã€‚</p>
        <p>"æ—¶é—´å°±æ˜¯é‡‘é’±ï¼Œæ•ˆç‡å°±æ˜¯ç”Ÿå‘½ã€‚"</p>
        <p>02</p>
        <p>åˆ¶å®šæ˜ç¡®çš„ç›®æ ‡æ˜¯æ—¶é—´ç®¡ç†çš„ç¬¬ä¸€æ­¥ã€‚</p>
        <p><strong>é‡è¦æé†’ï¼šæ¯å¤©æ—©ä¸ŠèŠ±5åˆ†é’Ÿè§„åˆ’å½“å¤©çš„ä»»åŠ¡ã€‚</strong></p>
    </div>
    """
    
    cleaned_content = agent._preprocess_content(html_content)
    print("åŸå§‹HTMLå†…å®¹:")
    print(html_content[:200] + "...")
    print("\né¢„å¤„ç†åå†…å®¹:")
    print(cleaned_content)
    print("\n" + "="*50)

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†æœºåˆ¶"""
    print("=== æµ‹è¯•é”™è¯¯å¤„ç†æœºåˆ¶ ===")
    
    agent = ContentAnalystAgent()
    
    print("1. æ— æ•ˆJSONå“åº”æµ‹è¯•:")
    invalid_json_state = create_test_state("æµ‹è¯•å†…å®¹è¶³å¤Ÿé•¿")
    
    with patch.object(agent, 'call_llm', return_value="è¿™ä¸æ˜¯æœ‰æ•ˆçš„JSON"):
        try:
            invalid_result = agent.execute(invalid_json_state)
            print(f"  æ‰§è¡ŒçŠ¶æ€: {invalid_result.current_step}")
            print(f"  é”™è¯¯ä¿¡æ¯: {invalid_result.errors}")
            print(f"  æœ€åé”™è¯¯: {invalid_result.last_error}")
        except Exception as e:
            print(f"  æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {str(e)}")
    
    print("\n2. ç¼ºå°‘å­—æ®µçš„JSONå“åº”æµ‹è¯•:")
    incomplete_json = '{"structure": {"title": "test"}}'  # ç¼ºå°‘å¿…è¦å­—æ®µ
    
    with patch.object(agent, 'call_llm', return_value=incomplete_json):
        try:
            incomplete_result = agent.execute(invalid_json_state)
            print(f"  æ‰§è¡ŒçŠ¶æ€: {incomplete_result.current_step}")
            print(f"  é”™è¯¯ä¿¡æ¯: {incomplete_result.errors}")
        except Exception as e:
            print(f"  æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {str(e)}")
    
    print("\n3. APIè°ƒç”¨å¤±è´¥æµ‹è¯•:")
    with patch.object(agent, 'call_llm', side_effect=Exception("APIè°ƒç”¨å¤±è´¥")):
        try:
            api_fail_result = agent.execute(invalid_json_state)
            print(f"  æ‰§è¡ŒçŠ¶æ€: {api_fail_result.current_step}")
            print(f"  é”™è¯¯ä¿¡æ¯: {api_fail_result.errors}")
        except Exception as e:
            print(f"  æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {str(e)}")
    
    print("\n" + "="*50)

def test_content_analysis_with_mock():
    """ä½¿ç”¨Mockæµ‹è¯•å†…å®¹åˆ†æåŠŸèƒ½"""
    print("=== æµ‹è¯•å†…å®¹åˆ†æåŠŸèƒ½ (Mock GPT-4) ===")
    
    # æ¨¡æ‹ŸGPT-4è¿”å›çš„åˆ†æç»“æœ
    mock_gpt4_response = json.dumps({
        "structure": {
            "content_type": "personal_advice",
            "total_sections": 2,
            "title": "æ—¶é—´ç®¡ç†çš„è‰ºæœ¯",
            "sections": [
                {
                    "section_number": "01",
                    "title": "æ—¶é—´çš„ä»·å€¼",
                    "content_type": "philosophical_reflection",
                    "emotional_tone": "motivational",
                    "key_elements": ["quote", "philosophy"]
                },
                {
                    "section_number": "02", 
                    "title": "ç›®æ ‡åˆ¶å®š",
                    "content_type": "practical_advice",
                    "emotional_tone": "instructional",
                    "key_elements": ["action_call", "emphasis"]
                }
            ]
        },
        "content_elements": {
            "quotes": [
                {
                    "text": "æ—¶é—´å°±æ˜¯é‡‘é’±ï¼Œæ•ˆç‡å°±æ˜¯ç”Ÿå‘½ã€‚",
                    "emotional_category": "motivational",
                    "context": "å…³äºæ—¶é—´ä»·å€¼çš„ç»å…¸è¡¨è¿°"
                }
            ],
            "emphasis_points": [
                {
                    "text": "æ¯å¤©æ—©ä¸ŠèŠ±5åˆ†é’Ÿè§„åˆ’å½“å¤©çš„ä»»åŠ¡",
                    "importance_level": "high",
                    "type": "action_call"
                }
            ],
            "action_recommendations": [
                {
                    "text": "åˆ¶å®šæ˜ç¡®çš„ç›®æ ‡",
                    "category": "time_management",
                    "practicality": "high"
                }
            ],
            "author_info": {
                "text": "",
                "type": "none"
            }
        },
        "visual_design_needs": {
            "hierarchy_requirements": {
                "title_prominence": "high",
                "section_differentiation": "strong",
                "quote_styling": "distinctive", 
                "emphasis_treatment": "highlight"
            },
            "bauhaus_features_needed": {
                "geometric_elements": True,
                "color_coding": True,
                "structured_layouts": True,
                "typography_hierarchy": True
            }
        }
    }, ensure_ascii=False)
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€
    test_content = """
    æ—¶é—´ç®¡ç†çš„è‰ºæœ¯
    
    01
    æ—¶é—´æ˜¯æœ€çè´µçš„èµ„æºï¼Œæ¯ä¸ªäººéƒ½æ‹¥æœ‰ç›¸åŒçš„24å°æ—¶ã€‚
    "æ—¶é—´å°±æ˜¯é‡‘é’±ï¼Œæ•ˆç‡å°±æ˜¯ç”Ÿå‘½ã€‚"
    
    02
    åˆ¶å®šæ˜ç¡®çš„ç›®æ ‡æ˜¯æ—¶é—´ç®¡ç†çš„ç¬¬ä¸€æ­¥ã€‚
    é‡è¦æé†’ï¼šæ¯å¤©æ—©ä¸ŠèŠ±5åˆ†é’Ÿè§„åˆ’å½“å¤©çš„ä»»åŠ¡ã€‚
    """
    
    state = create_test_state(test_content)
    agent = ContentAnalystAgent()
    
    # Mock GPT-4 è°ƒç”¨
    with patch.object(agent, 'call_llm', return_value=mock_gpt4_response):
        result_state = agent.execute(state)
    
    print("è¾“å…¥å†…å®¹:")
    print(test_content)
    print("\næ‰§è¡ŒçŠ¶æ€:")
    print(f"current_step: {result_state.current_step}")
    print(f"é”™è¯¯æ•°é‡: {len(result_state.errors)}")
    
    print("\nåˆ†æç»“æœ:")
    if result_state.content_analysis_summary:
        print("ç»“æ„åˆ†æ:")
        structure = result_state.content_analysis_summary.get("structure", {})
        print(f"  - å†…å®¹ç±»å‹: {structure.get('content_type')}")
        print(f"  - ç« èŠ‚æ•°é‡: {structure.get('total_sections')}")
        print(f"  - æ ‡é¢˜: {structure.get('title')}")
        
        print("\nå†…å®¹å…ƒç´ :")
        elements = result_state.content_analysis_summary.get("content_elements", {})
        print(f"  - å¼•ç”¨æ•°é‡: {len(elements.get('quotes', []))}")
        print(f"  - å¼ºè°ƒç‚¹æ•°é‡: {len(elements.get('emphasis_points', []))}")
        print(f"  - è¡ŒåŠ¨å»ºè®®æ•°é‡: {len(elements.get('action_recommendations', []))}")
        
        print("\nè®¾è®¡éœ€æ±‚:")
        design_needs = result_state.content_analysis_summary.get("visual_design_needs", {})
        bauhaus_features = design_needs.get("bauhaus_features_needed", {})
        needed_features = [k for k, v in bauhaus_features.items() if v]
        print(f"  - éœ€è¦çš„åŒ…è±ªæ–¯ç‰¹å¾: {needed_features}")
    
    print("\nåä½œä¸Šä¸‹æ–‡:")
    context = result_state.collaboration_context.get("content_features", {})
    print(f"  - ç»“æ„å¤æ‚åº¦: {context.get('structure_complexity')}")
    print(f"  - æœ‰ç‰¹æ®Šå…ƒç´ : {context.get('has_special_elements')}")
    print(f"  - å†…å®¹ç±»å‹: {context.get('content_type')}")
    
    print("\n" + "="*50)

def test_validation_functions():
    """æµ‹è¯•éªŒè¯åŠŸèƒ½"""
    print("=== æµ‹è¯•éªŒè¯åŠŸèƒ½ ===")
    
    agent = ContentAnalystAgent()
    
    # æµ‹è¯•å‰ç½®æ¡ä»¶éªŒè¯
    print("1. å‰ç½®æ¡ä»¶éªŒè¯æµ‹è¯•:")
    
    # æœ‰æ•ˆçŠ¶æ€
    valid_state = create_test_state("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å†…å®¹ï¼Œé•¿åº¦è¶…è¿‡10ä¸ªå­—ç¬¦ã€‚")
    valid_result = agent.validate_preconditions(valid_state)
    print(f"  æœ‰æ•ˆçŠ¶æ€éªŒè¯: {valid_result}")
    
    # æ— æ•ˆçŠ¶æ€ - å†…å®¹å¤ªçŸ­
    invalid_state = create_test_state("çŸ­")
    invalid_result = agent.validate_preconditions(invalid_state)
    print(f"  å†…å®¹å¤ªçŸ­éªŒè¯: {invalid_result}")
    
    # æ— æ•ˆçŠ¶æ€ - ç¼ºå°‘style_requirements
    no_style_state = AgentState(
        task_id="test_task_002",
        original_content="æµ‹è¯•å†…å®¹",
        style_requirements={}  # ç©ºçš„style_requirements
    )
    no_style_result = agent.validate_preconditions(no_style_state)
    print(f"  ç¼ºå°‘é£æ ¼è¦æ±‚éªŒè¯: {no_style_result}")
    
    print("\n2. è¾“å‡ºéªŒè¯æµ‹è¯•:")
    
    # æœ‰æ•ˆè¾“å‡º
    state_with_analysis = create_test_state("æµ‹è¯•")
    state_with_analysis.content_analysis_summary = {
        "structure": {"total_sections": 1},
        "content_elements": {},
        "visual_design_needs": {}
    }
    valid_output = agent.validate_output(state_with_analysis)
    print(f"  æœ‰æ•ˆè¾“å‡ºéªŒè¯: {valid_output}")
    
    # æ— æ•ˆè¾“å‡º
    state_without_analysis = create_test_state("æµ‹è¯•")
    invalid_output = agent.validate_output(state_without_analysis)
    print(f"  æ— æ•ˆè¾“å‡ºéªŒè¯: {invalid_output}")
    
    print("\n" + "="*50)

def test_collaboration_feedback():
    """æµ‹è¯•åä½œåé¦ˆç”Ÿæˆ"""
    print("=== æµ‹è¯•åä½œåé¦ˆç”Ÿæˆ ===")
    
    agent = ContentAnalystAgent()
    
    # åˆ›å»ºåŒ…å«åˆ†æç»“æœçš„çŠ¶æ€
    state = create_test_state("æµ‹è¯•å†…å®¹")
    state.content_analysis_summary = {
        "structure": {
            "total_sections": 3,
            "content_type": "tutorial"
        },
        "content_elements": {
            "quotes": [{"text": "æµ‹è¯•å¼•ç”¨1"}, {"text": "æµ‹è¯•å¼•ç”¨2"}],
            "emphasis_points": [{"text": "é‡è¦æé†’"}]
        },
        "visual_design_needs": {
            "bauhaus_features_needed": {
                "geometric_elements": True,
                "color_coding": True,
                "structured_layouts": False,
                "typography_hierarchy": True
            }
        }
    }
    
    feedback = agent.get_collaboration_feedback(state)
    print("ç”Ÿæˆçš„åä½œåé¦ˆ:")
    print(feedback)
    
    print("\nåé¦ˆè§£æ:")
    feedback_parts = feedback.split("; ") if feedback else []
    for i, part in enumerate(feedback_parts, 1):
        print(f"  {i}. {part}")
    
    print("\n" + "="*50)

def test_real_content_from_file():
    """ä½¿ç”¨ test/test.html çš„çœŸå®å†…å®¹æµ‹è¯•"""
    print("=== ä½¿ç”¨çœŸå®æµ‹è¯•æ•°æ®æµ‹è¯• ContentAnalyst ===")
    
    # è¯»å–çœŸå®æµ‹è¯•æ–‡ä»¶
    try:
        with open('../test/test.html', 'r', encoding='utf-8') as f:
            real_content = f.read()
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ°æµ‹è¯•æ–‡ä»¶ ../test/test.html")
        return
    
    print("çœŸå®æµ‹è¯•å†…å®¹é¢„è§ˆ:")
    print(real_content[:300] + "..." if len(real_content) > 300 else real_content)
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€
    state = create_test_state(real_content, "åŒ…è±ªæ–¯é£æ ¼")
    agent = ContentAnalystAgent()
    
    print("\nå†…å®¹é¢„å¤„ç†ç»“æœ:")
    cleaned_content = agent._preprocess_content(real_content)
    print("é¢„å¤„ç†åçš„æ–‡æœ¬å†…å®¹:")
    print(cleaned_content[:500] + "..." if len(cleaned_content) > 500 else cleaned_content)
    
    # æ¨¡æ‹ŸContentAnalystå¯¹è¿™ä¸ªçœŸå®å†…å®¹çš„åˆ†æ
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸è°ƒç”¨çœŸå®çš„GPT-4ï¼Œè€Œæ˜¯æ¨¡æ‹Ÿä¸€ä¸ªåˆç†çš„åˆ†æç»“æœ
    mock_analysis = {
        "structure": {
            "content_type": "personal_experience_sharing",
            "total_sections": 3,
            "title": "å¤±ä¸šä¸€å¹´ï¼šé‚£äº›æ‰“ä¸æ­»æˆ‘çš„ï¼Œèƒ½ä¸èƒ½åˆ«å†æ‰“æˆ‘äº†",
            "sections": [
                {
                    "section_number": "01",
                    "title": "å¤±ä¸šç°çŠ¶æè¿°",
                    "content_type": "problem_identification",
                    "emotional_tone": "empathetic_understanding",
                    "key_elements": ["quotes", "common_struggles"]
                },
                {
                    "section_number": "02", 
                    "title": "åº”å¯¹æ–¹æ³•å»ºè®®",
                    "content_type": "practical_solutions",
                    "emotional_tone": "encouraging_guidance",
                    "key_elements": ["action_recommendations", "time_management"]
                },
                {
                    "section_number": "03",
                    "title": "å¿ƒæ€è°ƒæ•´æ€è€ƒ",
                    "content_type": "mindset_transformation", 
                    "emotional_tone": "philosophical_reflection",
                    "key_elements": ["quotes", "identity_redefinition"]
                }
            ]
        },
        "content_elements": {
            "quotes": [
                {
                    "text": "å¤±ä¸šä»¥åï¼Œæ¯å¤©çªåœ¨å‡ºç§Ÿå±‹ï¼Œæ—¥å¤œé¢ å€’ï¼Œç²¾ç¥è¶Šæ¥è¶Šèé¡ï¼Œå¥½åƒçªç„¶ä¸çŸ¥é“è¯¥å¹²å˜›äº†ã€‚",
                    "emotional_category": "frustrated",
                    "context": "æè¿°å¤±ä¸šçŠ¶æ€çš„å…¸å‹è¡¨ç°"
                },
                {
                    "text": "æˆ‘ä¸çŸ¥é“è‡ªå·±è¦å¹²å˜›ï¼Œæˆ‘ä¹Ÿä¸çŸ¥é“æˆ‘è‡ªå·±æƒ³å¹²å˜›ã€‚",
                    "emotional_category": "confused",
                    "context": "è¡¨è¾¾å†…å¿ƒçš„è¿·èŒ«"
                },
                {
                    "text": "æ—¶é—´æ˜¯å½¢è€Œä¸Šçš„é¦–è¦é—®é¢˜ã€‚",
                    "emotional_category": "philosophical",
                    "context": "å¯¹æ—¶é—´æœ¬è´¨çš„å“²å­¦æ€è€ƒ"
                }
            ],
            "emphasis_points": [
                {
                    "text": "ä¸è¦æ€»åœ¨å±‹å­é‡Œå¾…ç€ï¼Œå‡ºé—¨ï¼Œç»™æˆ‘å‡ºé—¨ï¼ä¸‹é›¨éƒ½ç»™æˆ‘æ‰“ä¼å‡ºé—¨ï¼",
                    "importance_level": "critical",
                    "type": "action_call"
                },
                {
                    "text": "åˆ«æŠŠè‡ªå·±å½“æˆä¸€ä¸ªå¤±ä¸šçš„äºº",
                    "importance_level": "high", 
                    "type": "core_message"
                },
                {
                    "text": "å…ˆå»æ‰¾åˆ°çŠ¶æ€ï¼Œæ‰¾åˆ°è‡ªå·±ï¼Œè¿™æ¯”æ‰¾åˆ°å·¥ä½œæ›´ä¸ºé‡è¦",
                    "importance_level": "critical",
                    "type": "life_philosophy"
                }
            ],
            "action_recommendations": [
                {
                    "text": "æ¯å¤©å›ºå®šå¥½ã€Œæ‰¾å·¥ä½œã€çš„æ—¶é—´",
                    "category": "time_management",
                    "practicality": "high"
                },
                {
                    "text": "æŠŠã€Œæ‰¾å·¥ä½œã€å½“æˆä¸€é¡¹å·¥ä½œï¼Œåˆ°ç‚¹ä¸‹ç­ï¼Œåˆ°å‘¨æœ«å°±ä¼‘æ¯",
                    "category": "work_life_balance",
                    "practicality": "high"
                },
                {
                    "text": "å†¥æƒ³ã€è¿åŠ¨ã€ç»ƒå­—ã€‚è¿™äº›éƒ½å¯¹è®­ç»ƒä¸“æ³¨åŠ›æœ‰ç”¨",
                    "category": "skill_development", 
                    "practicality": "high"
                }
            ],
            "author_info": {
                "text": "æˆ‘æ˜¯çš®çš®ç–ï¼Œæ²ªæ¼‚10å¹´ï¼Œç›®å‰å¤±ä¸šä¸­ã€‚è¿™æ˜¯ç¬¬89ç¯‡åŸåˆ›æ–‡",
                "type": "personal_introduction"
            }
        },
        "visual_design_needs": {
            "hierarchy_requirements": {
                "title_prominence": "very_high",
                "section_differentiation": "strong_numbered_sections",
                "quote_styling": "emotional_differentiation",
                "emphasis_treatment": "strong_action_highlights"
            },
            "bauhaus_features_needed": {
                "geometric_elements": True,
                "color_coding": True,
                "structured_layouts": True, 
                "typography_hierarchy": True
            }
        }
    }
    
    print(f"\n=== æ¨¡æ‹Ÿçš„ ContentAnalyst åˆ†æç»“æœ ===")
    
    # ä½¿ç”¨Mockæµ‹è¯•
    with patch.object(agent, 'call_llm', return_value=json.dumps(mock_analysis, ensure_ascii=False)):
        result_state = agent.execute(state)
    
    print(f"æ‰§è¡ŒçŠ¶æ€: {result_state.current_step}")
    print(f"æ˜¯å¦æˆåŠŸ: {result_state.current_step == 'content_analysis_completed'}")
    print(f"é”™è¯¯æ•°é‡: {len(result_state.errors)}")
    
    if result_state.content_analysis_summary:
        analysis = result_state.content_analysis_summary
        
        print(f"\nğŸ“Š å†…å®¹ç»“æ„åˆ†æ:")
        structure = analysis["structure"]
        print(f"  - å†…å®¹ç±»å‹: {structure['content_type']}")
        print(f"  - æ–‡ç« æ ‡é¢˜: {structure['title']}")
        print(f"  - ç« èŠ‚æ•°é‡: {structure['total_sections']}")
        
        print(f"\n  ç« èŠ‚è¯¦æƒ…:")
        for i, section in enumerate(structure['sections'], 1):
            print(f"    ç¬¬{i}èŠ‚ ({section['section_number']}): {section['title']}")
            print(f"           ç±»å‹: {section['content_type']}, æƒ…æ„Ÿ: {section['emotional_tone']}")
        
        print(f"\nğŸ¯ å†…å®¹å…ƒç´ è¯†åˆ«:")
        elements = analysis["content_elements"]
        print(f"  - è¯†åˆ«åˆ° {len(elements['quotes'])} ä¸ªå¼•ç”¨:")
        for i, quote in enumerate(elements['quotes'], 1):
            print(f"    {i}. \"{quote['text'][:50]}...\" [{quote['emotional_category']}]")
        
        print(f"  - è¯†åˆ«åˆ° {len(elements['emphasis_points'])} ä¸ªå¼ºè°ƒç‚¹:")
        for i, emp in enumerate(elements['emphasis_points'], 1):
            print(f"    {i}. {emp['text'][:50]}... [{emp['importance_level']}]")
        
        print(f"  - è¯†åˆ«åˆ° {len(elements['action_recommendations'])} ä¸ªè¡ŒåŠ¨å»ºè®®:")
        for i, action in enumerate(elements['action_recommendations'], 1):
            print(f"    {i}. {action['text'][:50]}... [{action['category']}]")
        
        print(f"\nğŸ¨ è§†è§‰è®¾è®¡éœ€æ±‚:")
        design_needs = analysis["visual_design_needs"]
        hierarchy = design_needs["hierarchy_requirements"]
        print(f"  - æ ‡é¢˜çªå‡ºéœ€æ±‚: {hierarchy['title_prominence']}")
        print(f"  - ç« èŠ‚åŒºåˆ†éœ€æ±‚: {hierarchy['section_differentiation']}")
        print(f"  - å¼•ç”¨æ ·å¼éœ€æ±‚: {hierarchy['quote_styling']}")
        print(f"  - å¼ºè°ƒå¤„ç†éœ€æ±‚: {hierarchy['emphasis_treatment']}")
        
        bauhaus_features = design_needs["bauhaus_features_needed"]
        needed_features = [k for k, v in bauhaus_features.items() if v]
        print(f"  - éœ€è¦çš„åŒ…è±ªæ–¯ç‰¹å¾: {needed_features}")
    
    print(f"\nğŸ¤ åä½œä¸Šä¸‹æ–‡:")
    context = result_state.collaboration_context.get("content_features", {})
    for key, value in context.items():
        print(f"  - {key}: {value}")
    
    print(f"\nğŸ“¢ ç»™ StyleDesigner çš„åä½œåé¦ˆ:")
    feedback = agent.get_collaboration_feedback(result_state)
    print(f"  {feedback}")
    
    print(f"\nğŸ’¡ è¿™ä¸ªåˆ†æçš„æ„ä¹‰:")
    print(f"  - StyleDesigner å°†åŸºäºè¿™ä¸ªåˆ†æè®¾è®¡ {structure['total_sections']} ç§ä¸åŒçš„ç« èŠ‚é¢œè‰²")
    print(f"  - å°†ä¸º {len(elements['quotes'])} ä¸ªå¼•ç”¨è®¾è®¡ä¸åŒçš„è¾¹æ¡†æ ·å¼")
    print(f"  - å°†ä¸º {len(elements['emphasis_points'])} ä¸ªå¼ºè°ƒç‚¹è®¾è®¡çªå‡ºçš„èƒŒæ™¯æ ·å¼")
    print(f"  - æ•´ä½“é‡‡ç”¨åŒ…è±ªæ–¯çš„å‡ ä½•åŒ–ã€ç»“æ„åŒ–è®¾è®¡è¯­è¨€")
    
    print("\n" + "="*50)

def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("=== æµ‹è¯•è¾¹ç•Œæƒ…å†µ ===")
    
    agent = ContentAnalystAgent()
    
    # æµ‹è¯•1: ç©ºå†…å®¹
    print("1. ç©ºå†…å®¹æµ‹è¯•:")
    empty_state = create_test_state("")
    empty_result = agent.validate_preconditions(empty_state)
    print(f"  ç©ºå†…å®¹éªŒè¯ç»“æœ: {empty_result}")
    
    # æµ‹è¯•2: çº¯HTMLæ ‡ç­¾
    print("\n2. çº¯HTMLæ ‡ç­¾æµ‹è¯•:")
    html_only = "<div><p></p></div>"
    html_state = create_test_state(html_only)
    cleaned_html = agent._preprocess_content(html_only)
    print(f"  æ¸…ç†åå†…å®¹: '{cleaned_html}'")
    
    # æµ‹è¯•3: ç‰¹æ®Šå­—ç¬¦å†…å®¹
    print("\n3. ç‰¹æ®Šå­—ç¬¦æµ‹è¯•:")
    special_content = "æµ‹è¯•å†…å®¹åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼š@#$%^&*()ï¼Œä»¥åŠemojiğŸ˜€ğŸ‰"
    special_cleaned = agent._preprocess_content(special_content)
    print(f"  ç‰¹æ®Šå­—ç¬¦å†…å®¹: {special_cleaned}")
    
    # æµ‹è¯•4: æ— æ•ˆJSONå“åº”å¤„ç†
    print("\n4. æ— æ•ˆJSONå“åº”å¤„ç†æµ‹è¯•:")
    invalid_json_state = create_test_state("æµ‹è¯•å†…å®¹è¶³å¤Ÿé•¿")
    
    with patch.object(agent, 'call_llm', return_value="è¿™ä¸æ˜¯æœ‰æ•ˆçš„JSON"):
        try:
            invalid_result = agent.execute(invalid_json_state)
            print(f"  æ‰§è¡ŒçŠ¶æ€: {invalid_result.current_step}")
            print(f"  æ˜¯å¦æ­£ç¡®å¤„ç†é”™è¯¯: {invalid_result.current_step == 'content_analysis_failed'}")
            print(f"  é”™è¯¯ä¿¡æ¯: {invalid_result.last_error}")
        except Exception as e:
            print(f"  å¼‚å¸¸å¤„ç†: {str(e)}")
    
    print("\n" + "="*50)

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ContentAnalyst Agent è°ƒè¯•æµ‹è¯•")
    print("="*60)
    
    try:
        # é¦–å…ˆæµ‹è¯•çœŸå®æ•°æ®
        test_real_content_from_file()
        
        # ç„¶åè¿è¡Œå…¶ä»–æµ‹è¯•
        test_html_preprocessing()
        test_error_handling()
        test_validation_functions()
        test_collaboration_feedback()
        test_content_analysis_with_mock()
        test_edge_cases()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("\nContentAnalystå·¥ä½œåŸç†æ€»ç»“:")
        print("1. æ¥æ”¶åŸå§‹å†…å®¹ â†’ 2. HTMLé¢„å¤„ç† â†’ 3. GPT-4æ·±åº¦åˆ†æ")
        print("4. ç»“æ„åŒ–è¾“å‡ºéªŒè¯ â†’ 5. åä½œä¸Šä¸‹æ–‡è®¾ç½® â†’ 6. åé¦ˆç”Ÿæˆ")
        print("7. å¤±è´¥æ—¶ç›´æ¥æŠ›å‡ºé”™è¯¯ï¼Œä¸ä½¿ç”¨æ— æ„ä¹‰çš„å¤‡ç”¨ç»“æœ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()